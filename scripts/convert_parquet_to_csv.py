# -*- coding: utf-8 -*-
"""
====================================
@File Name : convert_parquet_to_csv.py
@Description : Utility script to read Parquet files (generated by display_grid_01_29.py) 
               and merge them into a single CSV file.
====================================
"""

import argparse
import os
import glob
import pandas as pd
import sys

def main():
    parser = argparse.ArgumentParser(description="Convert Parquet log files to a single CSV.")
    parser.add_argument("--input", "-i", type=str, required=True, 
                        help="Input path. Can be a directory (containing .parquet files or a 'parquet_parts' folder) or a single .parquet file.")
    parser.add_argument("--output", "-o", type=str, default=None, 
                        help="Output CSV file path. If not specified, saves to the same level as input with .csv extension.")
    
    args = parser.parse_args()
    input_path = args.input

    # 1. Identify Parquet files
    parquet_files = []
    
    if os.path.isfile(input_path):
        if input_path.endswith(".parquet"):
            parquet_files.append(input_path)
        else:
            print(f"[ERROR] Input file '{input_path}' is not a .parquet file.")
            sys.exit(1)
    elif os.path.isdir(input_path):
        # Look for parquet files directly in dir
        files_in_dir = glob.glob(os.path.join(input_path, "*.parquet"))
        
        # Look for parquet files in 'parquet_parts' subdir (structure from display_grid logs)
        files_in_subdir = glob.glob(os.path.join(input_path, "parquet_parts", "*.parquet"))
        
        parquet_files.extend(files_in_dir)
        parquet_files.extend(files_in_subdir)
        
        parquet_files = sorted(list(set(parquet_files))) # Remove duplicates and sort
    else:
        print(f"[ERROR] Input path '{input_path}' does not exist.")
        sys.exit(1)

    if not parquet_files:
        print(f"[ERROR] No .parquet files found in '{input_path}'.")
        print("Expected structure: logs/.../parquet_parts/part-XXXXX.parquet")
        sys.exit(1)

    print(f"[INFO] Found {len(parquet_files)} parquet files to process.")

    # 2. Read and Concatenate
    dfs = []
    try:
        for f in parquet_files:
            print(f"  -> Reading {os.path.basename(f)}...", end="\r")
            df = pd.read_parquet(f, engine='pyarrow')
            dfs.append(df)
        print(f"\n[INFO] All files read successfully.")
    except Exception as e:
        print(f"\n[ERROR] Failed reading parquet file: {e}")
        try:
            import pyarrow
        except ImportError:
            print("[HINT] Ensure 'pyarrow' is installed: pip install pyarrow")
        sys.exit(1)

    if not dfs:
        print("[WARN] No data frames loaded.")
        sys.exit(0)

    full_df = pd.concat(dfs, ignore_index=True)
    print(f"[INFO] Merged DataFrame shape: {full_df.shape}")

    # 3. Determine Output Path
    if args.output:
        output_csv = args.output
    else:
        # Default name based on input dir/file
        # If the input is a log directory (contains 'parquet_parts'), we want the CSV in the same level as meta.json
        # i.e. input_path/basename_merged.csv
        
        # Check if we are inside a parquet_parts directory or the parent log directory
        abs_input = os.path.abspath(input_path)
        base_name = os.path.basename(abs_input)
        
        if os.path.isdir(abs_input):
            if base_name == "parquet_parts":
                # input is logs/.../parquet_parts
                # output should be logs/.../logs_merged.csv
                parent_dir = os.path.dirname(abs_input)
                parent_name = os.path.basename(parent_dir)
                output_csv = os.path.join(parent_dir, f"raw_{parent_name}_merged.csv")
            elif os.path.exists(os.path.join(abs_input, "parquet_parts")):
                # input is logs/.../
                # output should be logs/.../logs_merged.csv
                # ideally next to meta.json
                output_csv = os.path.join(abs_input, f"raw_{base_name}_merged.csv")
            else:
                # just a folder with parquet files
                output_csv = os.path.join(abs_input, f"raw_{base_name}_merged.csv")
                
        elif os.path.isfile(abs_input):
            # input is a single file
            output_csv = os.path.splitext(abs_input)[0] + ".csv"
        else:
             # Fallback
            output_csv = f"raw_{base_name}_merged.csv"
    
    # Ensure output dir exists
    out_dir = os.path.dirname(output_csv)
    if out_dir and not os.path.exists(out_dir):
        os.makedirs(out_dir)

    # 4. Save to CSV
    print(f"[INFO] Saving to CSV: {output_csv} ...")
    full_df.to_csv(output_csv, index=False)
    print("[INFO] Done.")

if __name__ == "__main__":
    main()
